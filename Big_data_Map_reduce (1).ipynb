{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gs5Knhz8wIw9",
        "outputId": "396ee8e4-4b39-4a7e-eec0-4e5c70e57724"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyhadoop\n",
            "  Downloading pyhadoop-0.1.tar.gz (2.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pyhadoop\n",
            "  Building wheel for pyhadoop (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyhadoop: filename=pyhadoop-0.1-py3-none-any.whl size=2742 sha256=65d0d9db5e6a0d51491683e1d3c581d92cda53f37735cd1596760019e85cc55f\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/cb/96/1ea6ed56366f0b284d0adae89e26844f70c30919355b398ac8\n",
            "Successfully built pyhadoop\n",
            "Installing collected packages: pyhadoop\n",
            "Successfully installed pyhadoop-0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyhadoop"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the mapper fn\n",
        "def mapper(input_data):\n",
        "  words=input_data.split()\n",
        "  return [(word,1) for word in words]\n",
        "\n",
        "#Define the reducer fn\n",
        "def reducer(mapped_data):\n",
        "  word_count={}\n",
        "  #aggregate key value pairs\n",
        "  for key, value in mapped_data:\n",
        "    word_count[key]=word_count.get(key,0)+value\n",
        "  return word_count\n",
        "\n",
        "#simple input data\n",
        "input_data=\"Map Reduce is a programming model for processing large dataset.\"\n",
        "\n",
        "#run the mapper\n",
        "mapped_data=mapper(input_data)\n",
        "print(\"Mapped Data:\")\n",
        "print(mapped_data)\n",
        "\n",
        "#run the reducer\n",
        "reduced_data=reducer(mapped_data)\n",
        "print(\"\\nReduced data:\")\n",
        "print(reduced_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b75IC8y6zYF4",
        "outputId": "fa3a54e1-67e3-4c7c-f436-a5ea592f59fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mapped Data:\n",
            "[('Map', 1), ('Reduce', 1), ('is', 1), ('a', 1), ('programming', 1), ('model', 1), ('for', 1), ('processing', 1), ('large', 1), ('dataset.', 1)]\n",
            "\n",
            "Reduced data:\n",
            "{'Map': 1, 'Reduce': 1, 'is': 1, 'a': 1, 'programming': 1, 'model': 1, 'for': 1, 'processing': 1, 'large': 1, 'dataset.': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define faulty mapper fn\n",
        "def faulty_mapper(input_data):\n",
        "  words=input_data.split()\n",
        "  return [(word,1) for word in words]\n",
        "\n",
        "#Define reducer\n",
        "def reducer(mapped_data):\n",
        "  word_count={}\n",
        "  #aggregate key value pairs\n",
        "  for key, value in mapped_data:\n",
        "    if value is None:  #debugging case\n",
        "      print(f\"Debug: Missing value for key'(key)'\")\n",
        "      continue\n",
        "    word_count[key]=word_count.get(key,0)+value\n",
        "  return word_count\n",
        "\n",
        "#Debugging the issue\n",
        "input_data=\"Debugging MapReduce programs are essential.\"\n",
        "\n",
        "#run the mapper\n",
        "mapped_data=faulty_mapper(input_data)\n",
        "print(\"Mapped Data with Issue:\")\n",
        "print(mapped_data)\n",
        "\n",
        "reduced_data=reducer(mapped_data)\n",
        "print(\"\\nFinal Reduced data(after handling errors):\")\n",
        "print(reduced_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akFdB69NB-20",
        "outputId": "ea73b7bc-5212-4f93-d2c1-8e98609c0534"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mapped Data with Issue:\n",
            "[('Debugging', 1), ('MapReduce', 1), ('programs', 1), ('are', 1), ('essential.', 1)]\n",
            "\n",
            "Final Reduced data(after handling errors):\n",
            "{'Debugging': 1, 'MapReduce': 1, 'programs': 1, 'are': 1, 'essential.': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Pipeline"
      ],
      "metadata": {
        "id": "aUH1y0lrKoXk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#function to process structured data(CSV)\n",
        "def process_structured_data(data):\n",
        "    structured_rows=[line.split(\",\") for line in data.split(\"\\n\")]\n",
        "    return [{\"ID\": row[0], \"Name\": row[1], \"Age\": int(row[2])} for row in structured_rows]\n",
        "\n",
        "#function to process unstructured data(text)\n",
        "def process_unstructured_data(data):\n",
        "    words =data.split(\"\\n\")\n",
        "    return [(word,1) for word in words]\n",
        "\n",
        "#Example data\n",
        "structured_data=\"1,John,28\\n2,Mary,22\\n3,Peter,35\"\n",
        "unstructured_data=\"MapReduce processes both structured and unstructured data efficiently\"\n",
        "\n",
        "#Processing\n",
        "structured_result=process_structured_data(structured_data)\n",
        "unstructured_result=process_unstructured_data(unstructured_data)\n",
        "\n",
        "#Displaying\n",
        "print(\" Processed Structured Data: \")\n",
        "print(structured_result)\n",
        "print(\"\\nProcessed Unstructured Data: \")\n",
        "print(unstructured_result)"
      ],
      "metadata": {
        "id": "L63iQxHw-f-Q",
        "outputId": "3455f739-9af1-4b3e-d220-fe722ab4924d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Processed Structured Data: \n",
            "[{'ID': '1', 'Name': 'John', 'Age': 28}, {'ID': '2', 'Name': 'Mary', 'Age': 22}, {'ID': '3', 'Name': 'Peter', 'Age': 35}]\n",
            "\n",
            "Processed Unstructured Data: \n",
            "[('MapReduce processes both structured and unstructured data efficiently', 1)]\n"
          ]
        }
      ]
    }
  ]
}